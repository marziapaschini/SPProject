{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0548a980",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "In this file, the dataset is processed to make it suitable for the subsequent machine learning analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d29a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73377b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0467c59c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataframe column names\n",
    "#print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fb575b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1caacd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric and categoric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number])\n",
    "numeric_cols = numeric_cols.drop(numeric_cols.columns[0], axis=1)\n",
    "categoric_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "categoric_cols = pd.Index(categoric_cols).delete([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69387a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Numeric columns: \", numeric_cols.columns)\n",
    "#print(\"\\nCategoric columns: \", categoric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c87ebc",
   "metadata": {},
   "source": [
    "Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f13350cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numeric_correlation(df, numeric_cols):\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title(\"Correlation matrix\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f46bcbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "#df_numeric_cols.remove('Unnamed: 0')\n",
    "#plot_numeric_correlation(df, df_numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109a9ee",
   "metadata": {},
   "source": [
    "#### Missing and null data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dd90d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing numeric data\n",
    "def missing_numeric_data(df, numeric_cols):\n",
    "    missing_data = df.isnull().sum()\n",
    "    print(\"Missing data per column:\")\n",
    "    print(missing_data)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(missing_data.index, missing_data.values)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Columns\")\n",
    "    plt.ylabel(\"Missing data\")\n",
    "    plt.title(\"Missing data per column\")\n",
    "    plt.show()\n",
    "\n",
    "# missing categoric data\n",
    "def missing_categoric_data(df, categoric_cols):\n",
    "    missing_data = df[categoric_cols].isnull().sum()\n",
    "    print(\"Missing data per column:\")\n",
    "    print(missing_data)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(missing_data.index, missing_data.values)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Columns\")\n",
    "    plt.ylabel(\"Missing data\")\n",
    "    plt.title(\"Missing data per column\")\n",
    "    plt.xticks(rotation=15)\n",
    "    plt.show()\n",
    "    \n",
    "def nan_values_check(df):\n",
    "    num_nan = df.isnull().sum()\n",
    "    return num_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "898f0215",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#missing_numeric_data(df, numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c2b461",
   "metadata": {},
   "source": [
    "`Evaporation` and `Sunshine` have more than 60% of missing data.<br>\n",
    "`Cloud9am` and `Cloud3pm` have about 30% of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cd445f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#missing_categoric_data(df, categoric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676fc89",
   "metadata": {},
   "source": [
    "`WindGustDir` and `WindDir9am` have about 12% of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b36ff711",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(nan_values_check(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3bd20",
   "metadata": {},
   "source": [
    "#### Data cleaning and reduction\n",
    "Functions to remove useless columns, fill by mean values, fill by most common value, remove rows with no prediction (i.e. \"RainTomorrow\" values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "424266c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, columns):\n",
    "    return df.drop(columns=columns, inplace=False)\n",
    "\n",
    "def fill_missing_values_with_mean(df, columns, groupby):\n",
    "    for col in columns:\n",
    "        df[col] = df.groupby(groupby)[col].transform(lambda x: x.fillna(x.mean()))\n",
    "    return df\n",
    "\n",
    "def fill_missing_values_with_mode(df, columns, groupby=None):\n",
    "    for col in columns:\n",
    "        if groupby is not None:\n",
    "            df[col] = df.groupby(groupby)[col].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df\n",
    "\n",
    "def remove_rows_with_missing_values(df, subset):\n",
    "    return df.dropna(subset=subset, inplace=False)\n",
    "\n",
    "def check_missing_values(df):\n",
    "    if df.isnull().sum().any():\n",
    "        return false\n",
    "    else:\n",
    "        return \"Null values: \" + str(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91fc5ce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = remove_columns(df, [\"Unnamed: 0\", \"Date\", \"Evaporation\", \"Sunshine\", \"RISK_MM\"])\n",
    "#print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7157d771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = fill_missing_values_with_mean(df, [\"MinTemp\", \"MaxTemp\", \"Rainfall\", \"WindSpeed9am\", \"WindSpeed3pm\", \"Humidity9am\", \"Humidity3pm\", \"Temp9am\", \"Temp3pm\"], \"Location\")\n",
    "df = fill_missing_values_with_mode(df, [\"WindDir9am\", \"WindDir3pm\"], \"Location\")\n",
    "df = fill_missing_values_with_mode(df, [\"Cloud9am\", \"Cloud3pm\", \"WindGustSpeed\", \"Pressure9am\", \"Pressure3pm\", \"WindGustDir\"])\n",
    "df = remove_rows_with_missing_values(df, [\"RainToday\"])\n",
    "\n",
    "df = remove_columns(df, [\"Location\"])\n",
    "#print(check_missing_values(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65cfaad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update sub-dataframes\n",
    "numeric_cols = df.select_dtypes(include=[np.number])\n",
    "categoric_cols = df.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7db0f9",
   "metadata": {},
   "source": [
    "Functions to identify and smooth **outliers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3429ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numeric_columns_boxplot(df):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(numeric_cols.values)\n",
    "    ax.set_title('Numeric columns boxplot')\n",
    "    ax.set_xticklabels(numeric_cols.columns, rotation=45)\n",
    "    ax.set_ylabel('Values')\n",
    "    plt.show()\n",
    "    \n",
    "def replace_outliers_with_mobile_mean(df, column_name, window_size, std_dev):\n",
    "    # compute mean mobile value\n",
    "    mean_mobile = df[column_name].rolling(window_size).mean()\n",
    "    # replace outliers with mean mobile value\n",
    "    outlier_threshold = std_dev * df[column_name].std()\n",
    "    outliers = abs(df[column_name] - df[column_name].shift()) > outlier_threshold\n",
    "    df.loc[outliers, column_name] = mean_mobile[outliers]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1496ec42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot_numeric_columns_boxplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42d47812",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = replace_outliers_with_mobile_mean(df, 'Rainfall', 2, 7)\n",
    "#plot_numeric_columns_boxplot(numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc8480",
   "metadata": {},
   "source": [
    "#### Data transformation\n",
    "Functions to perform data types conversion and applying dummies to categoric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51dbff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'RainToday' and 'RainTomorrow': from 'Yes'/No' to 'True'/'False'\n",
    "def data_types_conversion(df, bool_columns=[]):\n",
    "    if bool_columns:\n",
    "        for col in bool_columns:\n",
    "            df[col] = df[col].map({'No': False, 'Yes': True})\n",
    "    return df\n",
    "\n",
    "def dummies_processing(df):\n",
    "    cat_cols = ['WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
    "    X_cat = df[cat_cols]\n",
    "    X_cat = pd.get_dummies(X_cat, drop_first=True)\n",
    "    X_cat['RainToday'] = df['RainToday']\n",
    "    X_cat['RainTomorrow'] = df['RainTomorrow']\n",
    "    return X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50be8f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data_types_conversion(df, bool_columns=['RainToday', 'RainTomorrow'])\n",
    "#print(\"NaN: \\n\", nan_values_check(df))\n",
    "X_categoric = dummies_processing(df)\n",
    "X_numeric = df[['MinTemp', 'MaxTemp', 'Rainfall', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm', 'Pressure9am', 'Pressure3pm']]\n",
    "#print(nan_values_check(X_categoric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57a56d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_categoric.columns)\n",
    "#print(X_numeric.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf80237b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pre-processed dataframe\n",
    "X = pd.concat([X_numeric, X_categoric], axis=1)\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c81e2",
   "metadata": {},
   "source": [
    "#### Columns selection\n",
    "For the final dataset, only the most important and user-friendly columns are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82936174",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[:, ['MinTemp', 'MaxTemp', 'Rainfall', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'RainToday', 'RainTomorrow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41af7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"Humidity\"] = pd.concat([X[\"Humidity9am\"], X[\"Humidity3pm\"]], axis=1).mean(axis=1)\n",
    "X = X.drop(['Humidity9am', 'Humidity3pm'], axis=1)\n",
    "X[\"WindSpeed\"] = pd.concat([X[\"WindSpeed9am\"], X[\"WindSpeed3pm\"]], axis=1).mean(axis=1)\n",
    "X = X.drop(['WindSpeed9am', 'WindSpeed3pm'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56e20f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MinTemp', 'MaxTemp', 'Rainfall', 'RainToday', 'RainTomorrow',\n",
      "       'Humidity', 'WindSpeed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
